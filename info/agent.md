# ğŸ¤– AI Agent System Design (For YouTube Summarizer Project)

## ğŸ§  Project Goal
An AI service that can summarize a YouTube video and let users chat with it like a tutor.

Your FastAPI service will be **multi-agent**, where each agent has a **specific role**.  
Weâ€™ll design it in a way thatâ€™s **scalable, clean, and easy to extend later** (like CrowAI or CrewAI style).

---

## ğŸ¤– Recommended Agents (Final Design)

You should start with **3 main agents** for your MVP â€” enough to make it smart, but still efficient.

Then, you can optionally add 2 more later.

---

### ğŸ¥ 1ï¸âƒ£ VideoFetcher Agent
**Purpose:**  
Extract the transcript and metadata from YouTube.

**Input:**  
- YouTube video URL  

**Output:**  
- Transcript text  
- Video title, duration, channel name  

**Implementation notes:**  
- Use `youtube-transcript-api` or `pytube`
- Cache the result in Redis

**Example Output:**
```json
{ 
  "title": "AI Tutorial",
  "duration": "15:23",
  "transcript": "Welcome to this tutorial on artificial intelligence..."
}
```

---

### âœï¸ 2ï¸âƒ£ Summarizer Agent
**Purpose:**  
Turn transcript into a clean summary.

**Input:**  
- Transcript text  

**Output:**  
- Short summary, long summary, or bullet points  

**Implementation notes:**  
- Use LLM (Gemini, OpenAI, Claude, etc.)
- Allow style selection later (e.g. â€œeducationalâ€, â€œkey pointsâ€, â€œfunnyâ€)
- Store summary in DB via NestJS callback

**Example Output:**
```json
{
  "summary": "This video explains how AI models learn from data...",
  "key_points": ["Machine learning basics", "Training data importance"]
}
```

---

### ğŸ’¬ 3ï¸âƒ£ Tutor Agent
**Purpose:**  
Let the user **chat** with the summary like a tutor.

**Input:**  
- User question  
- Summary (context)  

**Output:**  
- Natural, contextual answer  

**Implementation notes:**  
- Keep conversation context in short-term memory (in Redis)
- Can cite summary parts in responses
- Uses same LLM but with â€œteacherâ€ style prompts

**Example Conversation:**
```
User: "Explain the math part more."
Agent: "The video mentions that the model adjusts weights during training..."
```

---

## ğŸ§  (Optional) Expansion Agents (Phase 2)

### ğŸ—‚ 4ï¸âƒ£ Memory Agent
**Purpose:**  
Store long-term conversation context or user preferences.

**Input:**  
- User ID + conversation logs  
**Output:**  
- Retrieved memory context  

**Implementation:**  
- Store summary history in DB (through NestJS)
- Retrieve past context for same video

---

### ğŸ•µï¸ 5ï¸âƒ£ Analyzer Agent
**Purpose:**  
Detect video type and adjust summary tone.

**Example:**  
- If educational â†’ structured notes  
- If music â†’ key lyrics or meaning  
- If tech â†’ code examples  

**Implementation:**  
Use simple text classification (LLM or keyword-based)

---

## ğŸ§© Agent Workflow Diagram

```
User
 â†“
Frontend
 â†“
NestJS (Main Service)
 â†“
FastAPI (AI Service)
 â”œâ”€â”€ VideoFetcher Agent â†’ gets transcript
 â”œâ”€â”€ Summarizer Agent â†’ creates summary
 â””â”€â”€ Tutor Agent â†’ chats with user about summary
```

---

## âš™ï¸ FastAPI Structure Example

```
/ai_service
 â”œâ”€ /agents
 â”‚   â”œâ”€ video_fetcher.py
 â”‚   â”œâ”€ summarizer.py
 â”‚   â”œâ”€ tutor.py
 â”‚   â””â”€ __init__.py
 â”œâ”€ main.py
 â”œâ”€ routers/
 â”‚   â”œâ”€ ai_router.py
 â”‚   â””â”€ internal.py
 â”œâ”€ /core
 â”‚   â”œâ”€ llm_client.py
 â”‚   â””â”€ cache.py
 â””â”€ requirements.txt
```

---

## ğŸ§  Agent Example Code Structure (Pseudo)

```python
# summarizer_agent.py
from core.llm_client import LLMClient

class SummarizerAgent:
    def __init__(self):
        self.llm = LLMClient()

    async def summarize(self, transcript: str) -> dict:
        prompt = f"Summarize this transcript clearly:\n{transcript[:4000]}"
        summary = await self.llm.generate(prompt)
        return {"summary": summary}
```

---

## ğŸ§© Recommended Agent Count (Final)

| Agent | MVP | Future |
|--------|------|--------|
| ğŸ¥ VideoFetcher | âœ… | âœ… |
| âœï¸ Summarizer | âœ… | âœ… |
| ğŸ’¬ Tutor | âœ… | âœ… |
| ğŸ§  Memory | âŒ | Optional later |
| ğŸ•µï¸ Analyzer | âŒ | Optional later |

âœ… **Total for MVP:** **3 agents**  
â³ **Later (Phase 2):** add 2 more for context + personalization
